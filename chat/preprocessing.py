
class preprocessing:
    def __init__(self, file_flag, opt):
        self.file_flag = file_flag
        self.opt = opt
        return

    def get_define(self, example):


        prenl = self.get_project_struct()

        prenl += self.get_example(example)
        
        return prenl
    
    def get_project_struct(self):
        only_one_table_op_exlain = [
            "read operator format: (Step N: Operator: read.\n Target columns: None.\n Operator: read.\n target steps:None.\n operation details: (1) use pandas to read table_1.csv As table_1, file_path is '/home/data/table_1.csv' (2) Perform data preprocessing on table_1.\n Step explanation: 'This step (1) reads a data file from the local system. (2) Perform data preprocessing on the data'\n",
            "join operator format: (Step N: Operator: join.\n Target columns: None.\n target steps: Step X, Step Y.\n operation details: Step X join Step Y on \"column1\" = \"column2\".)\n Step explanation: This step performs a join operation on the temporary views generated by two steps.\n"
            "filter operator format: (Step N: Operator: filter.\n Target columns: \"column1\".\n target steps: Step X.\n operation details: Filter Step X Where \"column1\" > X.)\n Step explanation: 'This step performs regular conditional comparisons on the results of the target step, excluding aggregate functions.'\n",
            "group_by operator format: (Step N: Operator: group_by.\n Target columns: \"column1\".\n target steps: Step X.\n operation details: group Step X by \"column1\".)\n Step explanation: This step is typically used in conjunction with 'having' operator, where aggregation function conditions are applied for filtering after grouping.\n",
            "having operator format: (Step N: Operator: having.\n Target columns: \"column1\".\n target steps: Step X.\n operation details: Step X having max(\"column1\") > 10.)\n Step explanation: This step is used for conditional filtering related to aggregate functions, and it usually needs to be combined with 'group_by'  operator for grouped aggregation filtering.\n",  
            "select operator format: (Step N: Operator: select.\n Target columns: \"column1\", \"column2\".\n target steps: Step X.\n operation details: Select \"column1\",\"column2\" from Step X.)\n Step explanation: 'This step involves selecting specific columns from the target view to generate a new view, typically used for choosing result columns or as condition columns.'\n",
            "order_by operator format: (Step N: Operator: order_by.\n Target columns: \"column1\".\n target steps: Step X.\n operation details: Order Step X by \"column1\" ASC.)\n Step explanation: 'This step sorts the output of Step X based on the specified column, where the column name is followed by the keywords ASC or DESC to represent ascending or descending order, respectively.'\n",
            "limit operator format: (Step N: Operator: limit.\n Target columns: None.\n target steps: Step X.\n operation details: limit x, y on Step X.)\n Step explanation: This step retrieves a specified number of rows from the output of the target step. Here, 'x' represents the number of rows to be retrieved, and 'y' represents the offset.\n"
            "write operator format: (Step N: Operator: write.\n Target columns: None.\n target steps: Step X.\n operation details: write Step X to result_path.)\n Step explanation: This step is typically the final one, as it saves the results of the entire data analysis to a specified txt file.\n"
        ]

        op_exlain = [
            "read operator format: (Step N: Operator: read.\n Target columns: None.\n Operator: read.\n target steps:None.\n operation details: (1) use pandas to read table_1.csv As table_1 (note:Just remove the .csv in name and don't change the case), file_path is '/home/data/table_1.csv' (2) Perform data preprocessing on table_1.\n Step explanation: 'This step (1) reads a data file from the local system, sets a view name, and all subsequent operations must target the data file read in this step. (2) Perform data preprocessing on the data'\n",
            "join operator format: (Step N: Operator: join.\n Target columns: None.\n target steps: Step X, Step Y.\n operation details: Step X join Step Y on table_1.column1 = table_2.column2.)\n Step explanation: This step performs a join operation on the temporary views generated by two steps.\n The table names and column names involved in the join conditions use the original names to avoid confusion, for example: 'Reviews.business_id = Business.business_id'.\n"
            "filter operator format: (Step N: Operator: filter.\n Target columns: table_1.column1.\n target steps: Step X.\n operation details: Filter Step X Where table_1.column1 > X.)\n Step explanation: 'This step performs regular conditional comparisons on the results of the target step, excluding aggregate functions.'\n",
            "concat operator format: (Step N: Operator: concat.\n Target columns: None.\n target steps: Step X, Step Y.\n operation details: Concat Step X and Step Y.)\n Step explanation: This step concatenates the temporary views generated by two steps, meaning it combines the columns of the two temporary tables.\n"
            "group_by operator format: (Step N: Operator: group_by.\n Target columns: table_1.column_1.\n target steps: Step X.\n operation details: group Step X by table_1.column_1.)\n Step explanation: This step is typically used in conjunction with 'having' operator, where aggregation function conditions are applied for filtering after grouping.\n",
            "having operator format: (Step N: Operator: having.\n Target columns: table_1.column_1.\n target steps: Step X.\n operation details: Step X having max(table_1.column_1) > 10.)\n Step explanation: This step is used for conditional filtering related to aggregate functions, and it usually needs to be combined with 'group_by'  operator for grouped aggregation filtering.\n",  
            "select operator format: (Step N: Operator: select.\n Target columns: table_1.column1, table_2.column2.\n target steps: Step X.\n operation details: Select table_1.column1,table_2.column2 from Step X.)\n Step explanation: 'This step involves selecting specific columns from the target view to generate a new view, typically used for choosing result columns.'\n",
            "order_by operator format: (Step N: Operator: order_by.\n Target columns: table_1.column1.\n target steps: Step X.\n operation details: Order Step X by table_1.column1 ASC.)\n Step explanation: 'This step sorts the output of Step X based on the specified column, where the column name is followed by the keywords ASC or DESC to represent ascending or descending order, respectively.'\n",
            "limit operator format: (Step N: Operator: limit.\n Target columns: None.\n target steps: Step X.\n operation details: limit x, y on Step X.)\n Step explanation: This step retrieves a specified number of rows from the output of the target step. Here, 'x' represents the number of rows to be retrieved, and 'y' represents the offset.\n"
            "write operator format: (Step N: Operator: write.\n Target columns: None.\n target steps: Step X.\n operation details: write Step X to result_path.)\n Step explanation: This step is typically the final one, as it saves the results of the entire data analysis to a specified txt file.\n"
            "distinct operator format: (Step N: Operator: distinct.\n Target columns: None.\n target steps: Step X.\n operation details: Distinct Step X.)\n Step explanation: This operator is exclusively used for applying DISTINCT to the entire query. If you want to manipulate specific columns, please specify them in the select operation details.\n",
        ]

        prenl = "Now, I will need you to undergo a data analysis process. I will provide information or requirements one by one. Please remember the relevant information and complete the corresponding tasks according to the given instructions:\n"
       
        prenl += "## 1.First, I have defined a set of logical plan syntax. Please remember them and generate logical plans according to this syntax when I subsequently ask you to do so. The syntax for logical plans is as follows:\n"
        
    
        prenl +=  "#(1) Syntax 1: Every step in the logical plan should be represented by an operator (indicating the operation to be performed in this step, with only one operation per step), target columns (indicating the columns on which the operation is performed for this step, can be empty), target steps (indicating further operations on the results of which steps for this step, can be empty), operation details (indicating the specific operation for this step, cannot be empty).\n"

       
        prenl += "#(2) Syntax 2: The operators mentioned in Syntax 2, along with their corresponding step formats and explanations for each step, are provided below:\n"
         
        for ex in op_exlain:
            prenl += ex
      
        prenl += "\n#(3) Syntax 3: During the process of generating the entire logical plan, please follow the logic of SQL queries using operators. Typically, each SELECT implies a query or subquery.."
    
        prenl += "#(4) Syntax 4: Please note that, due to the possibility of multiple tables having the same column names, when referencing column names throughout the logical plan generation, use the \"table_name.column_name\" format to specify the table_name. The table_name should be the actual CSV data table being manipulated, as specified in the 'AS' clause of the 'read' operator.\n"
        
        prenl += "For example, in the operation details of the 'read' operator: \"use pandas to read Business.csv As Business\", the subsequent reference to its column names, such as 'business_id', should be expressed as 'Business.business_id'.\n"

        prenl += "#(5) Syntax 5: Please try to adhere to the following priority order as much as possible in the entire logical plan steps. Operations with higher priority should be executed first to ensure a clearer and more readable logical plan:"

        prenl += "read operator > join operator > filter operator > select operator > write operator.\n "

        prenl += "Priority Explanation: The entire logical plan should begin by using 'read' operations to fetch data from all needed data file, followed by performing all necessary join operations to create a large temporary view. Subsequently, use some filter operations on this view based on the specified conditions, then employ the \"select\" operation to choose the columns required for the result, and finally, utilize the \"write\" operator to write the results to a file. The order of operators not mentioned in the above priority order can be placed according to practical needs as deemed reasonable.\n"

        prenl += "#(6) Syntax 6: The 'Perform data preprocessing' within the read operator does not involve specific operations during the logical planning phase. Corresponding code will be generated during the code generation phase.\n"
        
        prenl += "#(7) Syntax 7: Note that in logical plan, intermediate results may be generated (such as subqueries in SQL). Therefore, the data manipulated by operators can be the result of any step, and the target step can also be the result of any preceding step, not necessarily the one immediately before.\n"
       
        return prenl
   
    
    def get_example(self, example):
        prenl = "\nBelow is an example of the logical plan:\n"
       
        prenl += example

        prenl += "\nThe example logical plan end.\n"
        return prenl
